"""
Voice Conversation Assistant
-------------------------------------------
A simplified voice conversation assistant focused on core functionality:
1. Voice/Text input
2. AI processing
3. Voice/Text output

This script provides both text-based and voice-based conversation modes.
"""
import os
import sys
import io
import time
import pathlib
from dotenv import load_dotenv

# Import voice assistant modules
from voice_assistant.real_speech_to_text import record_and_transcribe
from voice_assistant.text_to_speech import synthesize_speech
from voice_assistant.ai_service import generate_response

# Load environment variables
load_dotenv()

# Set console encoding to UTF-8
try:
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stdin = io.TextIOWrapper(sys.stdin.buffer, encoding='utf-8')
except Exception as e:
    print(f"Warning: Could not set encoding: {e}")
    # Continue anyway


def run_voice_assistant(system_prompt="ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹"):
    """Run the voice-based assistant with voice input and output."""
    messages = [{"role": "system", "content": system_prompt}]
    
    count = 0
    EXIT_PHRASES = {"ç»“æŸ", "é€€å‡º", "æ‹œæ‹œ", "å†è§", "break out", "bye", "exit", "quit"}
    
    print("=" * 50)
    print("è¯­éŸ³å¯¹è¯åŠ©æ‰‹ (Voice Conversation Assistant)")
    print("=" * 50)
    print("æç¤º: ç³»ç»Ÿå°†æç¤ºæ‚¨å¼€å§‹è¯´è¯ï¼Œè¯·åœ¨æç¤ºåå¯¹ç€éº¦å…‹é£è¯´è¯")
    print("      å½“æ‚¨è¯´è¯æ—¶ï¼Œå±å¹•å°†æ˜¾ç¤ºâ€œæ­£åœ¨å€’å¬â€çŠ¶æ€")
    print("      å¦‚æœè¯­éŸ³è¯†åˆ«å¤±è´¥ï¼Œæ‚¨å¯ä»¥ç›´æ¥è¾“å…¥æ–‡å­—")
    print("      è¯´'é€€å‡º'æˆ–'exit'ç»“æŸå¯¹è¯")
    print("=" * 50)
    
    try:
        while True:
            count += 1
            print("\n" + "-" * 40)
            print(f"[å¯¹è¯ #{count}]")
            print("-" * 40)
            print("\nâ€¢ å‡†å¤‡å¼€å§‹...")
            print("\nğŸ¤ è¯·å¼€å§‹è¯´è¯ (ç³»ç»Ÿå°†è‡ªåŠ¨æ£€æµ‹æ‚¨ä½•æ—¶å¼€å§‹è¯´è¯)")
            
            # Try to get speech input with a timeout
            try:
                user_text = record_and_transcribe(duration=5, language="zh-CN")
            except Exception as e:
                print(f"\nâŒ è¯­éŸ³è¯†åˆ«å‡ºé”™: {e}")
                user_text = ""
                
            # If speech recognition failed, fall back to text input
            if not user_text:
                print("\nâŒ æœªèƒ½è¯†åˆ«è¯­éŸ³ï¼Œè¯·ç›´æ¥è¾“å…¥æ–‡å­—:")
                try:
                    print("âŒ¨ï¸ > ", end="")
                    user_text = input()
                except (EOFError, KeyboardInterrupt):
                    print("\nâŒ ç”¨æˆ·ç»ˆæ­¢ï¼Œé€€å‡º")
                    break
                    
                if not user_text:
                    print("\nâŒ æœªè·å–åˆ°è¾“å…¥ï¼Œè¯·é‡è¯•")
                    continue
                
            print(f"\nğŸ—£ æ‚¨è¯´: {user_text}")
            
            # Check if user wants to exit
            if any(exit_phrase in user_text.lower() for exit_phrase in EXIT_PHRASES):
                print("\nğŸš« æ£€æµ‹åˆ°é€€å‡ºæŒ‡ä»¤ï¼Œç»“æŸå¯¹è¯")
                break
            
            # Add user message to conversation history
            messages.append({"role": "user", "content": user_text})
            
            # Generate AI response
            start_time = time.time()
            print("\nğŸ¤– AIæ­£åœ¨æ€è€ƒ...", end="", flush=True)
            
            # Start generating response with animation
            animation = ["â ‹", "â ™", "â ¹", "â ¸", "â ¼", "â ´", "â ¦", "â §", "â ‡", "â "]
            i = 0
            is_generating = True
            
            # Define a function to generate response
            def generate():
                nonlocal is_generating
                response = generate_response(messages)
                is_generating = False
                return response
                
            # Start generating in a separate thread if threading is available
            try:
                import threading
                thread = threading.Thread(target=lambda: globals().update({'ai_response': generate()}))
                thread.daemon = True
                thread.start()
                
                # Show animation while generating
                while is_generating and thread.is_alive():
                    print(f"\rAIæ­£åœ¨æ€è€ƒ... {animation[i % len(animation)]}", end="", flush=True)
                    time.sleep(0.1)
                    i += 1
                thread.join()
                ai_response = globals().get('ai_response', '')
            except (ImportError, RuntimeError):
                # Fallback if threading is not available
                ai_response = generate_response(messages)
                is_generating = False
            
            # Calculate thinking time
            thinking_time = time.time() - start_time
            print(f"\rAIå·²å®Œæˆæ€è€ƒ ({thinking_time:.1f}ç§’)" + " "*30)
            
            # Display the response with proper formatting
            print(f"\n>> åŠ©æ‰‹å›å¤: {ai_response}")
            
            # Add assistant response to conversation history
            messages.append({"role": "assistant", "content": ai_response})
            
            # Convert AI response to speech
            print("\n>> æ­£åœ¨ç”Ÿæˆè¯­éŸ³å›å¤...")
            mp3_filename = f"response_{count}.mp3"
            
            # Track TTS start time
            tts_start = time.time()
            success = synthesize_speech(ai_response, mp3_filename)
            tts_time = time.time() - tts_start
            
            if success:
                print(f"\nâˆšâˆš è¯­éŸ³ç”Ÿæˆå®Œæˆ ({tts_time:.1f}ç§’)")
            else:
                print("\n!! è¯­éŸ³ç”Ÿæˆå¯èƒ½ä¸å®Œæ•´ï¼Œä½†å°†å°è¯•æ’­æ”¾å¯ç”¨éƒ¨åˆ†")
            
            # Play the generated speech
            try:
                # For Windows, use the default player
                audio_path = pathlib.Path("data") / mp3_filename
                
                if os.path.exists(audio_path):
                    print(f"\n>> æ­£åœ¨æ’­æ”¾è¯­éŸ³å›å¤...")
                os.startfile(audio_path)
                
                # Wait for audio to finish (approximate)
                words_per_second = 2.5  # Estimated speaking rate
                wait_time = min(len(ai_response.split()) / words_per_second, 30)  # Cap at 30 seconds
                
                # Simple progress indicator
                for i in range(int(wait_time)):
                    print(".", end="", flush=True)
                    time.sleep(1)
                print("\n\nâœ… è¯­éŸ³å›å¤å·²æ’­æ”¾å®Œæ¯•")  
                
            except AttributeError:
                # Fallback for non-Windows platforms
                if os.name == 'posix':
                    import subprocess
                    audio_path = pathlib.Path("data") / mp3_filename
                    print(f"\n>> æ­£åœ¨æ’­æ”¾è¯­éŸ³å›å¤...")
                    subprocess.run(["paplay", audio_path])
                    print("\nâœ… è¯­éŸ³å›å¤å·²æ’­æ”¾å®Œæ¯•")
                else:
                    print(f"\nğŸ’¾ è¯­éŸ³æ–‡ä»¶å·²ä¿å­˜è‡³ data/{mp3_filename}")
                    print("è¯·æ‰‹åŠ¨æ‰“å¼€æ–‡ä»¶æ”¶å¬å›å¤")
    
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ç»ˆæ­¢ï¼Œé€€å‡º")
    except Exception as e:
        print(f"å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    finally:
        print("\n" + "=" * 50)
        print("è¯­éŸ³åŠ©æ‰‹å·²å…³é—­")
        print("=" * 50)


def run_text_assistant(system_prompt="ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹", save_conversation=True):
    """Run the text-based assistant with text input and output."""
    # Initialize conversation
    messages = [{"role": "system", "content": system_prompt}]
    
    # Default exit phrases
    exit_phrases = {"ç»“æŸ", "é€€å‡º", "æ‹œæ‹œ", "å†è§", "break out", "bye", "exit", "quit"}
    
    count = 0
    conversation_log = []
    
    print("===== æ–‡æœ¬åŠ©æ‰‹å·²å¯åŠ¨ï¼Œè¯·å¼€å§‹å¯¹è¯ =====")
    print("ä½¿ç”¨æ–‡æœ¬è¾“å…¥æ¨¡å¼")
    print(f"è¾“å…¥ä»¥ä¸‹ä»»æ„è¯è¯­ç»“æŸå¯¹è¯: {', '.join(exit_phrases)}")
    
    try:
        while True:
            count += 1
            print("\nç­‰å¾…ç”¨æˆ·è¾“å…¥...")
            
            # Get user input (text only)
            print("> ", end="")
            user_text = input()
            if not user_text:
                print("æœªè·å–åˆ°è¾“å…¥ï¼Œè¯·é‡è¯•")
                continue
                
            print(f"ç”¨æˆ·: {user_text}")
            
            # Save to conversation log
            if save_conversation:
                conversation_log.append(f"ç”¨æˆ·: {user_text}")
            
            # Check if user wants to exit
            if any(exit_phrase in user_text.lower() for exit_phrase in exit_phrases):
                print("æ£€æµ‹åˆ°é€€å‡ºæŒ‡ä»¤ï¼Œç»“æŸå¯¹è¯")
                break
            
            # Add user message to conversation history
            messages.append({"role": "user", "content": user_text})
            
            # Generate AI response
            print("AIæ­£åœ¨æ€è€ƒ...")
            ai_response = generate_response(messages)
            print(f"åŠ©æ‰‹: {ai_response}")
            
            # Save to conversation log
            if save_conversation:
                conversation_log.append(f"åŠ©æ‰‹: {ai_response}")
            
            # Add assistant response to conversation history
            messages.append({"role": "assistant", "content": ai_response})
    
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ç»ˆæ­¢ï¼Œé€€å‡º")
    except Exception as e:
        print(f"å‘ç”Ÿé”™è¯¯: {e}")
    finally:
        print("è¯­éŸ³åŠ©æ‰‹å·²å…³é—­")
        
        # Save conversation history if enabled
        if save_conversation and conversation_log:
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"conversation_{timestamp}.txt"
            
            # Ensure data directory exists
            data_dir = pathlib.Path("data")
            data_dir.mkdir(exist_ok=True)
            
            # Save to data directory
            file_path = data_dir / filename
            with open(file_path, "w", encoding="utf-8") as f:
                f.write("\n".join(conversation_log))
            print(f"å¯¹è¯å†å²å·²ä¿å­˜è‡³ {file_path}")


def main():
    """Main entry point with mode selection."""
    print("=" * 50)
    print("è¯­éŸ³å¯¹è¯åŠ©æ‰‹ (Voice Conversation Assistant)")
    print("=" * 50)
    print("è¯·é€‰æ‹©æ¨¡å¼:")
    print("1. æ–‡æœ¬æ¨¡å¼ (é”®ç›˜è¾“å…¥/æ–‡æœ¬è¾“å‡º)")
    print("2. è¯­éŸ³æ¨¡å¼ (è¯­éŸ³è¾“å…¥/è¯­éŸ³è¾“å‡º)")
    print("=" * 50)
    
    choice = input("è¯·è¾“å…¥é€‰æ‹© (1 æˆ– 2): ")
    
    if choice == "1":
        run_text_assistant(system_prompt="ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ï¼Œè¯·ç®€æ´æ˜äº†åœ°å›ç­”é—®é¢˜")
    elif choice == "2":
        run_voice_assistant(system_prompt="ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ï¼Œè¯·ç®€æ´æ˜äº†åœ°å›ç­”é—®é¢˜")
    else:
        print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¿è¡Œç¨‹åºå¹¶é€‰æ‹© 1 æˆ– 2")

    print("      è¾“å…¥'é€€å‡º'æˆ–'exit'ç»“æŸå¯¹è¯")
    
    try:
        while True:
            count += 1
            print("\nç­‰å¾…ç”¨æˆ·è¾“å…¥...")
            
            # Get speech input and convert to text
            user_text = record_and_transcribe()
            if not user_text:
                print("æœªèƒ½è¯†åˆ«è¯­éŸ³ï¼Œè¯·é‡è¯•")
                continue
                
            print(f"ç”¨æˆ·: {user_text}")
            
            # Check if user wants to exit
            if any(exit_phrase in user_text.lower() for exit_phrase in EXIT_PHRASES):
                print("æ£€æµ‹åˆ°é€€å‡ºæŒ‡ä»¤ï¼Œç»“æŸå¯¹è¯")
                break
            
            # Add user message to conversation history
            messages.append({"role": "user", "content": user_text})
            
            # Generate AI response
            print("AIæ­£åœ¨æ€è€ƒ...")
            ai_response = generate_response(messages)
            print(f"åŠ©æ‰‹: {ai_response}")
            
            # Add assistant response to conversation history
            messages.append({"role": "assistant", "content": ai_response})
            
            # Convert AI response to speech
            print("ç”Ÿæˆè¯­éŸ³å›å¤...")
            mp3_filename = f"response_{count}.mp3"
            synthesize_speech(ai_response, mp3_filename)
            
            # Play the generated speech
            try:
                # For Windows, use the default player
                os.startfile(pathlib.Path(mp3_filename))
            except AttributeError:
                # Fallback for non-Windows platforms
                if os.name == 'posix':
                    subprocess.run(["paplay", pathlib.Path(mp3_filename)])
                else:
                    print(f"Generated speech saved to {mp3_filename}")
                    print("Please open the file manually to hear the response.")
    
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ç»ˆæ­¢ï¼Œé€€å‡º")
    except Exception as e:
        print(f"å‘ç”Ÿé”™è¯¯: {e}")
    finally:
        print("è¯­éŸ³åŠ©æ‰‹å·²å…³é—­")

if __name__ == "__main__":
    main()
